{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azure.cosmos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcosmos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CosmosClient, PartitionKey\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'azure.cosmos'"
     ]
    }
   ],
   "source": [
    "from azure.cosmos import CosmosClient, PartitionKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azure.cosmos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mConversation_model_RAG\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m store\n",
      "File \u001b[0;32m~/harshil/docker_test/MaricoGPT/Backend/Conversation_model_RAG.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_openai_callback\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HumanMessage, AIMessage\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcosmos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CosmosClient, PartitionKey  \n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcosmos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CosmosResourceNotFoundError\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mazuresearch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureSearch\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'azure.cosmos'"
     ]
    }
   ],
   "source": [
    "from Conversation_model_RAG import store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import creat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-storage-blob\n",
      "  Using cached azure_storage_blob-12.22.0-py3-none-any.whl (404 kB)\n",
      "Requirement already satisfied: azure-core>=1.28.0 in ./bvenv/lib/python3.10/site-packages (from azure-storage-blob) (1.30.2)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in ./bvenv/lib/python3.10/site-packages (from azure-storage-blob) (43.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in ./bvenv/lib/python3.10/site-packages (from azure-storage-blob) (4.12.2)\n",
      "Requirement already satisfied: isodate>=0.6.1 in ./bvenv/lib/python3.10/site-packages (from azure-storage-blob) (0.6.1)\n",
      "Requirement already satisfied: six>=1.11.0 in ./bvenv/lib/python3.10/site-packages (from azure-core>=1.28.0->azure-storage-blob) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in ./bvenv/lib/python3.10/site-packages (from azure-core>=1.28.0->azure-storage-blob) (2.32.3)\n",
      "Requirement already satisfied: cffi>=1.12 in ./bvenv/lib/python3.10/site-packages (from cryptography>=2.1.4->azure-storage-blob) (1.17.0)\n",
      "Requirement already satisfied: pycparser in ./bvenv/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./bvenv/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./bvenv/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (2024.7.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./bvenv/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./bvenv/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (2.2.2)\n",
      "Installing collected packages: azure-storage-blob\n",
      "Successfully installed azure-storage-blob-12.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install azure-storage-blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from azure.search.documents.indexes.models import (\n",
    "    ScoringProfile,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    TextWeights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient,generate_blob_sas,BlobSasPermissions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Using cached unstructured-0.15.7-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: psutil in ./bvenv/lib/python3.10/site-packages (from unstructured) (6.0.0)\n",
      "Collecting python-magic\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting chardet\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Requirement already satisfied: backoff in ./bvenv/lib/python3.10/site-packages (from unstructured) (2.2.1)\n",
      "Collecting lxml\n",
      "  Using cached lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "Collecting filetype\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting rapidfuzz\n",
      "  Using cached rapidfuzz-3.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "Requirement already satisfied: beautifulsoup4 in ./bvenv/lib/python3.10/site-packages (from unstructured) (4.12.3)\n",
      "Requirement already satisfied: wrapt in ./bvenv/lib/python3.10/site-packages (from unstructured) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions in ./bvenv/lib/python3.10/site-packages (from unstructured) (4.12.2)\n",
      "Requirement already satisfied: numpy<2 in ./bvenv/lib/python3.10/site-packages (from unstructured) (1.26.4)\n",
      "Requirement already satisfied: requests in ./bvenv/lib/python3.10/site-packages (from unstructured) (2.32.3)\n",
      "Collecting langdetect\n",
      "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
      "Requirement already satisfied: dataclasses-json in ./bvenv/lib/python3.10/site-packages (from unstructured) (0.6.7)\n",
      "Collecting python-iso639\n",
      "  Using cached python_iso639-2024.4.27-py3-none-any.whl (274 kB)\n",
      "Collecting unstructured-client\n",
      "  Using cached unstructured_client-0.25.5-py3-none-any.whl (43 kB)\n",
      "Requirement already satisfied: tqdm in ./bvenv/lib/python3.10/site-packages (from unstructured) (4.66.4)\n",
      "Collecting emoji\n",
      "  Using cached emoji-2.12.1-py3-none-any.whl (431 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./bvenv/lib/python3.10/site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./bvenv/lib/python3.10/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./bvenv/lib/python3.10/site-packages (from dataclasses-json->unstructured) (3.21.3)\n",
      "Requirement already satisfied: six in ./bvenv/lib/python3.10/site-packages (from langdetect->unstructured) (1.16.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./bvenv/lib/python3.10/site-packages (from nltk->unstructured) (2024.5.15)\n",
      "Requirement already satisfied: click in ./bvenv/lib/python3.10/site-packages (from nltk->unstructured) (8.1.7)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./bvenv/lib/python3.10/site-packages (from requests->unstructured) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./bvenv/lib/python3.10/site-packages (from requests->unstructured) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./bvenv/lib/python3.10/site-packages (from requests->unstructured) (2024.7.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./bvenv/lib/python3.10/site-packages (from requests->unstructured) (2.2.2)\n",
      "Collecting requests-toolbelt>=1.0.0\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (2.9.0.post0)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Requirement already satisfied: pypdf>=4.0 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (4.3.1)\n",
      "Collecting jsonpath-python>=1.0.6\n",
      "  Using cached jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Collecting deepdiff>=6.0\n",
      "  Using cached deepdiff-7.0.1-py3-none-any.whl (80 kB)\n",
      "Requirement already satisfied: packaging>=23.1 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (24.1)\n",
      "Collecting ordered-set<4.2.0,>=4.1.0\n",
      "  Using cached ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: sniffio in ./bvenv/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in ./bvenv/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.5)\n",
      "Requirement already satisfied: anyio in ./bvenv/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.4.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./bvenv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./bvenv/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.2.2)\n",
      "Installing collected packages: filetype, tabulate, rapidfuzz, python-magic, python-iso639, ordered-set, lxml, langdetect, jsonpath-python, joblib, emoji, chardet, requests-toolbelt, nltk, deepdiff, unstructured-client, unstructured\n",
      "Successfully installed chardet-5.2.0 deepdiff-7.0.1 emoji-2.12.1 filetype-1.2.0 joblib-1.4.2 jsonpath-python-1.0.6 langdetect-1.0.9 lxml-5.3.0 nltk-3.9.1 ordered-set-4.1.0 python-iso639-2024.4.27 python-magic-0.4.27 rapidfuzz-3.9.6 requests-toolbelt-1.0.0 tabulate-0.9.0 unstructured-0.15.7 unstructured-client-0.25.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "%pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-magic in ./bvenv/lib/python3.10/site-packages (0.4.27)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-pptx\n",
      "  Using cached python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in ./bvenv/lib/python3.10/site-packages (from python-pptx) (5.3.0)\n",
      "Collecting Pillow>=3.3.2\n",
      "  Using cached pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in ./bvenv/lib/python3.10/site-packages (from python-pptx) (4.12.2)\n",
      "Collecting XlsxWriter>=0.5.7\n",
      "  Using cached XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
      "Installing collected packages: XlsxWriter, Pillow, python-pptx\n",
      "Successfully installed Pillow-10.4.0 XlsxWriter-3.2.0 python-pptx-1.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-pptx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "connect_str = \"DefaultEndpointsProtocol=https;AccountName=maricogpt;AccountKey=qWBQYmrXPuHjMGcT3NUi9fZ+6AmPtJI2bKiX7CZ4uFsSY0IvPERIt35eBBeoPscXGG8VKPYRRK1t+ASt0V6R9w==;EndpointSuffix=core.windows.net\"\n",
    "container_name = \"maricogpt\"  \n",
    "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPowerPointLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders.azure_blob_storage_file import AzureBlobStorageFileLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://maricogpt.blob.core.windows.net/maricogpt/doc_ML Ops framework Update - Jan 2024.pptx_1dc9acb2-086e-4146-8240-b6ce1920ffe7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://maricogpt.blob.core.windows.net/maricogpt/doc_Digital_Image.pdf_f99a16b4-b376-43c1-a0bc-d378a413f70c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement urlparse (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for urlparse\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured[pdf] in ./bvenv/lib/python3.10/site-packages (0.15.7)\n",
      "Requirement already satisfied: chardet in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (5.2.0)\n",
      "Requirement already satisfied: requests in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (2.32.3)\n",
      "Requirement already satisfied: langdetect in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (1.0.9)\n",
      "Requirement already satisfied: emoji in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (2.12.1)\n",
      "Requirement already satisfied: numpy<2 in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (1.26.4)\n",
      "Requirement already satisfied: nltk in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (3.9.1)\n",
      "Requirement already satisfied: filetype in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (1.2.0)\n",
      "Requirement already satisfied: backoff in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (2.2.1)\n",
      "Requirement already satisfied: python-iso639 in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (2024.4.27)\n",
      "Requirement already satisfied: beautifulsoup4 in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (4.12.3)\n",
      "Requirement already satisfied: psutil in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (6.0.0)\n",
      "Requirement already satisfied: tabulate in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (0.9.0)\n",
      "Requirement already satisfied: tqdm in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (4.66.4)\n",
      "Requirement already satisfied: unstructured-client in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (0.25.5)\n",
      "Requirement already satisfied: wrapt in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (4.12.2)\n",
      "Requirement already satisfied: dataclasses-json in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (0.6.7)\n",
      "Requirement already satisfied: lxml in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (5.3.0)\n",
      "Requirement already satisfied: rapidfuzz in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (3.9.6)\n",
      "Requirement already satisfied: python-magic in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (0.4.27)\n",
      "Collecting unstructured.pytesseract>=0.3.12\n",
      "  Using cached unstructured.pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Collecting pikepdf\n",
      "  Using cached pikepdf-9.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "Collecting google-cloud-vision\n",
      "  Using cached google_cloud_vision-3.7.4-py2.py3-none-any.whl (467 kB)\n",
      "Collecting pdfminer.six\n",
      "  Using cached pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
      "Collecting onnx\n",
      "  Using cached onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
      "Collecting pillow-heif\n",
      "  Using cached pillow_heif-0.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "Collecting effdet\n",
      "  Using cached effdet-0.4.1-py3-none-any.whl (112 kB)\n",
      "Collecting unstructured-inference==0.7.36\n",
      "  Using cached unstructured_inference-0.7.36-py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: pypdf in ./bvenv/lib/python3.10/site-packages (from unstructured[pdf]) (4.3.1)\n",
      "Collecting pdf2image\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Collecting opencv-python!=4.7.0.68\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Collecting timm\n",
      "  Using cached timm-1.0.9-py3-none-any.whl (2.3 MB)\n",
      "Requirement already satisfied: onnxruntime>=1.17.0 in ./bvenv/lib/python3.10/site-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (1.18.1)\n",
      "Collecting torch\n",
      "  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m830.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:07\u001b[0m\n",
      "\u001b[?25hCollecting layoutparser\n",
      "  Using cached layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
      "Collecting transformers>=4.25.1\n",
      "  Using cached transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "Requirement already satisfied: huggingface-hub in ./bvenv/lib/python3.10/site-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (0.24.4)\n",
      "Requirement already satisfied: python-multipart in ./bvenv/lib/python3.10/site-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (0.0.9)\n",
      "Requirement already satisfied: packaging>=21.3 in ./bvenv/lib/python3.10/site-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (24.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in ./bvenv/lib/python3.10/site-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (10.4.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./bvenv/lib/python3.10/site-packages (from beautifulsoup4->unstructured[pdf]) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./bvenv/lib/python3.10/site-packages (from dataclasses-json->unstructured[pdf]) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./bvenv/lib/python3.10/site-packages (from dataclasses-json->unstructured[pdf]) (0.9.0)\n",
      "Collecting pycocotools>=2.0.2\n",
      "  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.8/427.8 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting omegaconf>=2.0\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in ./bvenv/lib/python3.10/site-packages (from google-cloud-vision->unstructured[pdf]) (2.32.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3\n",
      "  Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 KB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1\n",
      "  Downloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in ./bvenv/lib/python3.10/site-packages (from google-cloud-vision->unstructured[pdf]) (4.25.4)\n",
      "Requirement already satisfied: six in ./bvenv/lib/python3.10/site-packages (from langdetect->unstructured[pdf]) (1.16.0)\n",
      "Requirement already satisfied: click in ./bvenv/lib/python3.10/site-packages (from nltk->unstructured[pdf]) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./bvenv/lib/python3.10/site-packages (from nltk->unstructured[pdf]) (2024.5.15)\n",
      "Requirement already satisfied: joblib in ./bvenv/lib/python3.10/site-packages (from nltk->unstructured[pdf]) (1.4.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in ./bvenv/lib/python3.10/site-packages (from pdfminer.six->unstructured[pdf]) (43.0.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in ./bvenv/lib/python3.10/site-packages (from pdfminer.six->unstructured[pdf]) (3.3.2)\n",
      "Requirement already satisfied: Deprecated in ./bvenv/lib/python3.10/site-packages (from pikepdf->unstructured[pdf]) (1.2.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./bvenv/lib/python3.10/site-packages (from requests->unstructured[pdf]) (2024.7.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./bvenv/lib/python3.10/site-packages (from requests->unstructured[pdf]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./bvenv/lib/python3.10/site-packages (from requests->unstructured[pdf]) (2.2.2)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured[pdf]) (1.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured[pdf]) (2.9.0.post0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured[pdf]) (1.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured[pdf]) (1.0.0)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured[pdf]) (0.27.0)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured[pdf]) (1.0.6)\n",
      "Requirement already satisfied: deepdiff>=6.0 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured[pdf]) (7.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in ./bvenv/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (1.17.0)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in ./bvenv/lib/python3.10/site-packages (from deepdiff>=6.0->unstructured-client->unstructured[pdf]) (4.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in ./bvenv/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.63.2)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
      "  Downloading grpcio_status-1.66.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in ./bvenv/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.65.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./bvenv/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./bvenv/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./bvenv/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (4.9)\n",
      "Requirement already satisfied: sniffio in ./bvenv/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.3.1)\n",
      "Requirement already satisfied: anyio in ./bvenv/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./bvenv/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./bvenv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured[pdf]) (0.14.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in ./bvenv/lib/python3.10/site-packages (from omegaconf>=2.0->effdet->unstructured[pdf]) (6.0.1)\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: flatbuffers in ./bvenv/lib/python3.10/site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[pdf]) (24.3.25)\n",
      "Requirement already satisfied: sympy in ./bvenv/lib/python3.10/site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[pdf]) (1.13.1)\n",
      "Requirement already satisfied: coloredlogs in ./bvenv/lib/python3.10/site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[pdf]) (15.0.1)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (305 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.53.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Collecting safetensors\n",
      "  Downloading safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.5/435.5 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in ./bvenv/lib/python3.10/site-packages (from torch->unstructured-inference==0.7.36->unstructured[pdf]) (2024.6.1)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.0.0\n",
      "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in ./bvenv/lib/python3.10/site-packages (from torch->unstructured-inference==0.7.36->unstructured[pdf]) (3.1.4)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m870.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./bvenv/lib/python3.10/site-packages (from torch->unstructured-inference==0.7.36->unstructured[pdf]) (3.15.4)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 KB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tokenizers<0.20,>=0.19 in ./bvenv/lib/python3.10/site-packages (from transformers>=4.25.1->unstructured-inference==0.7.36->unstructured[pdf]) (0.19.1)\n",
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy\n",
      "  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting iopath\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pycparser in ./bvenv/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (2.22)\n",
      "Collecting grpcio<2.0dev,>=1.33.2\n",
      "  Downloading grpcio-1.66.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2\n",
      "  Downloading protobuf-5.27.3-cp38-abi3-manylinux2014_x86_64.whl (309 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.3/309.3 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./bvenv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.6.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./bvenv/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.2.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./bvenv/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[pdf]) (10.0)\n",
      "Requirement already satisfied: portalocker in ./bvenv/lib/python3.10/site-packages (from iopath->layoutparser->unstructured-inference==0.7.36->unstructured[pdf]) (2.10.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./bvenv/lib/python3.10/site-packages (from jinja2->torch->unstructured-inference==0.7.36->unstructured[pdf]) (2.1.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./bvenv/lib/python3.10/site-packages (from pandas->layoutparser->unstructured-inference==0.7.36->unstructured[pdf]) (2024.1)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pypdfium2>=4.18.0\n",
      "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pdfminer.six\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in ./bvenv/lib/python3.10/site-packages (from sympy->onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[pdf]) (1.3.0)\n",
      "Building wheels for collected packages: antlr4-python3-runtime, iopath\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144552 sha256=711d1a763dc0e09a0250bb54b2275ab8b208a18f974eca16e65b833019503b1e\n",
      "  Stored in directory: /home/admharshila/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "  Building wheel for iopath (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31531 sha256=ccebd11a8ef2cf889d9866dfb32ed197fc4d48590c6c70dfcfc54cfc81d39d0a\n",
      "  Stored in directory: /home/admharshila/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
      "Successfully built antlr4-python3-runtime iopath\n",
      "Installing collected packages: antlr4-python3-runtime, unstructured.pytesseract, tzdata, triton, scipy, safetensors, pypdfium2, pyparsing, protobuf, pillow-heif, pdf2image, opencv-python, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, kiwisolver, iopath, grpcio, fonttools, cycler, contourpy, proto-plus, pikepdf, pandas, onnx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, matplotlib, pycocotools, pdfminer.six, nvidia-cusolver-cu12, grpcio-status, google-api-core, transformers, torch, pdfplumber, torchvision, layoutparser, google-cloud-vision, timm, unstructured-inference, effdet\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.4\n",
      "    Uninstalling protobuf-4.25.4:\n",
      "      Successfully uninstalled protobuf-4.25.4\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.65.2\n",
      "    Uninstalling grpcio-1.65.2:\n",
      "      Successfully uninstalled grpcio-1.65.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opentelemetry-proto 1.26.0 requires protobuf<5.0,>=3.19, but you have protobuf 5.27.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 contourpy-1.2.1 cycler-0.12.1 effdet-0.4.1 fonttools-4.53.1 google-api-core-2.19.1 google-cloud-vision-3.7.4 grpcio-1.66.0 grpcio-status-1.66.0 iopath-0.1.10 kiwisolver-1.4.5 layoutparser-0.3.4 matplotlib-3.9.2 networkx-3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 onnx-1.16.2 opencv-python-4.10.0.84 pandas-2.2.2 pdf2image-1.17.0 pdfminer.six-20231228 pdfplumber-0.11.4 pikepdf-9.2.0 pillow-heif-0.18.0 proto-plus-1.24.0 protobuf-5.27.3 pycocotools-2.0.8 pyparsing-3.1.4 pypdfium2-4.30.0 safetensors-0.4.4 scipy-1.14.1 timm-1.0.9 torch-2.4.0 torchvision-0.19.0 transformers-4.44.2 triton-3.0.0 tzdata-2024.1 unstructured-inference-0.7.36 unstructured.pytesseract-0.3.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"unstructured[pdf]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse as urlparse\n",
    "\n",
    "def url_fix(s, charset='utf-8'):\n",
    "    # No need to check for 'unicode' in Python 3, just check for 'str'\n",
    "    if isinstance(s, str):\n",
    "        s = s.encode(charset, 'ignore')\n",
    "    scheme, netloc, path, qs, anchor = urlparse.urlsplit(s.decode(charset))\n",
    "    path = urlparse.quote(path, safe='/')\n",
    "    qs = urlparse.quote_plus(qs, safe=':&=')\n",
    "    return urlparse.urlunsplit((scheme, netloc, path, qs, anchor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://maricogpt.blob.core.windows.net/maricogpt/doc_ML_Ops_framework_Update_Jan_2024.pptx_1dc9acb2-086e-4146-8240-b6ce1920ffe7\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://maricogpt.blob.core.windows.net/maricogpt/doc_9th-SB.docx_321d7910-ac1b-4165-9641-5f8e4df745fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-pptx in ./bvenv/lib/python3.10/site-packages (1.0.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in ./bvenv/lib/python3.10/site-packages (from python-pptx) (5.3.0)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in ./bvenv/lib/python3.10/site-packages (from python-pptx) (10.4.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in ./bvenv/lib/python3.10/site-packages (from python-pptx) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in ./bvenv/lib/python3.10/site-packages (from python-pptx) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-pptx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured[docx] in ./bvenv/lib/python3.10/site-packages (0.15.7)\n",
      "Requirement already satisfied: python-iso639 in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (2024.4.27)\n",
      "Requirement already satisfied: rapidfuzz in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (3.9.6)\n",
      "Requirement already satisfied: beautifulsoup4 in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (4.12.3)\n",
      "Requirement already satisfied: wrapt in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (1.16.0)\n",
      "Requirement already satisfied: emoji in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (2.12.1)\n",
      "Requirement already satisfied: requests in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (2.32.3)\n",
      "Requirement already satisfied: backoff in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (2.2.1)\n",
      "Requirement already satisfied: chardet in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (5.2.0)\n",
      "Requirement already satisfied: python-magic in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (0.4.27)\n",
      "Requirement already satisfied: unstructured-client in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (0.25.5)\n",
      "Requirement already satisfied: dataclasses-json in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (0.6.7)\n",
      "Requirement already satisfied: tabulate in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (0.9.0)\n",
      "Requirement already satisfied: psutil in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (6.0.0)\n",
      "Requirement already satisfied: langdetect in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (1.0.9)\n",
      "Requirement already satisfied: filetype in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (1.2.0)\n",
      "Requirement already satisfied: numpy<2 in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (1.26.4)\n",
      "Requirement already satisfied: typing-extensions in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (4.12.2)\n",
      "Requirement already satisfied: lxml in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (5.3.0)\n",
      "Requirement already satisfied: nltk in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (3.9.1)\n",
      "Requirement already satisfied: tqdm in ./bvenv/lib/python3.10/site-packages (from unstructured[docx]) (4.66.4)\n",
      "Collecting python-docx>=1.1.2\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 KB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in ./bvenv/lib/python3.10/site-packages (from beautifulsoup4->unstructured[docx]) (2.5)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./bvenv/lib/python3.10/site-packages (from dataclasses-json->unstructured[docx]) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./bvenv/lib/python3.10/site-packages (from dataclasses-json->unstructured[docx]) (3.21.3)\n",
      "Requirement already satisfied: six in ./bvenv/lib/python3.10/site-packages (from langdetect->unstructured[docx]) (1.16.0)\n",
      "Requirement already satisfied: click in ./bvenv/lib/python3.10/site-packages (from nltk->unstructured[docx]) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./bvenv/lib/python3.10/site-packages (from nltk->unstructured[docx]) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./bvenv/lib/python3.10/site-packages (from nltk->unstructured[docx]) (2024.5.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./bvenv/lib/python3.10/site-packages (from requests->unstructured[docx]) (2024.7.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./bvenv/lib/python3.10/site-packages (from requests->unstructured[docx]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./bvenv/lib/python3.10/site-packages (from requests->unstructured[docx]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./bvenv/lib/python3.10/site-packages (from requests->unstructured[docx]) (2.2.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured[docx]) (1.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured[docx]) (1.0.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured[docx]) (1.6.0)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured[docx]) (1.0.6)\n",
      "Requirement already satisfied: pypdf>=4.0 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured[docx]) (4.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured[docx]) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging>=23.1 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured[docx]) (24.1)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured[docx]) (0.27.0)\n",
      "Requirement already satisfied: deepdiff>=6.0 in ./bvenv/lib/python3.10/site-packages (from unstructured-client->unstructured[docx]) (7.0.1)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in ./bvenv/lib/python3.10/site-packages (from deepdiff>=6.0->unstructured-client->unstructured[docx]) (4.1.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./bvenv/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[docx]) (1.0.5)\n",
      "Requirement already satisfied: anyio in ./bvenv/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[docx]) (4.4.0)\n",
      "Requirement already satisfied: sniffio in ./bvenv/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[docx]) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./bvenv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured[docx]) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./bvenv/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured[docx]) (1.2.2)\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-1.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"unstructured[docx]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pptx import Presentation\n",
    "\n",
    "# prs = Presentation(path_to_presentation)\n",
    "\n",
    "# # text_runs will be populated with a list of strings,\n",
    "# # one for each text run in presentation\n",
    "# text_runs = []\n",
    "\n",
    "# for slide in prs.slides:\n",
    "#     for shape in slide.shapes:\n",
    "#         if not shape.has_text_frame:\n",
    "#             continue\n",
    "#         for paragraph in shape.text_frame.paragraphs:\n",
    "#             for run in paragraph.runs:\n",
    "#                 text_runs.append(run.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In Query.jsx when user sends a message handle send in called, In handle send query_ai function return an object the object can be like this \n",
    "\n",
    "Object 1. user_input_required: 1. asm_area_name: (2) ['Rajasthan 1', 'Rajasthan 2'] 2. channel_name: ['GT'] 3. portfolio_name: ['Saffola Oils'] 4. [[Prototype]]: Object 2. [[Prototype]]: Object\n",
    "\n",
    "or \n",
    "\n",
    "{ 'main_result' : result, 'text': sql_query, 'data':data_dict }\n",
    "\n",
    "If the output is first object type i want to create a dynamic multi select dropdown for each user hit and if the object structure is same as mentioned.\n",
    "\n",
    "Here object.user_input_required.___ should be the title of dropdown and the values in it should be the dropdown values . There should also be a button to submit the user selected values. After submitting i  want the output as same format as the object 1 but with only the user selected values and when user press submit i want to call a FUnction to give the final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2\n",
      "Step 3\n",
      "Step 4\n",
      "https://maricogpt.blob.core.windows.net/maricogpt/doc_req.txt_321d7910-ac1b-4165-9641-5f8e4df745fc?se=2024-08-27T06%3A20%3A21Z&sp=r&sv=2024-08-04&sr=b&sig=Rx9BmD3iJMH7VroJZ8gtUXynvK67lEvE7zaDkEFLbfM%3D\n"
     ]
    }
   ],
   "source": [
    "sas_expiry = datetime.now() + timedelta(minutes=15)\n",
    "print(\"Step 2\")\n",
    "blob_name = \"doc_req.txt_321d7910-ac1b-4165-9641-5f8e4df745fc\"\n",
    "\n",
    "# Generate the SAS token\n",
    "sas_token = generate_blob_sas(\n",
    "    account_name=blob_service_client.account_name,\n",
    "    container_name=container_name,\n",
    "    blob_name= blob_name,\n",
    "    account_key=blob_service_client.credential.account_key,\n",
    "    permission=BlobSasPermissions(read=True),  # Set permissions (e.g., read)\n",
    "    expiry=sas_expiry\n",
    ")\n",
    "print(\"Step 3\")\n",
    "\n",
    "# Generate the SAS URL\n",
    "sas_url = f\"https://{blob_service_client.account_name}.blob.core.windows.net/{container_name}/{blob_name}?{sas_token}\"\n",
    "print(\"Step 4\")\n",
    "print(sas_url)\n",
    "# loader = UnstructuredPowerPointLoader(sas_url)\n",
    "# loader = PyPDFLoader(sas_url)\n",
    "loader = AzureBlobStorageFileLoader(conn_str=connect_str,container = container_name, blob_name=blob_name)\n",
    "pages = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(pages)\n",
    "\n",
    "# Retriever = await CreateRetriever(document_id= document_id,sas_url=sas_url)\n",
    "# print(\"Step 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '/tmp/tmpau38k8tr/maricogpt/doc_9th-SB.docx_321d7910-ac1b-4165-9641-5f8e4df745fc'}, page_content='IMPERIAL INTERNATIONAL SCHOOL, PALDHI\\n\\nClass – 9th\\tUnit Test 1and 2\\tDate : / /2024\\n\\nMarks - 20\\tSub – Geometry\\tTime – 45 mins\\n\\nA) Select the correct alternative and fill in the following statement.\\t(4)\\n\\nThe number of angles formed by transversal of two lines is... A) 2\\tB) 4\\tC) 6\\tD) 8\\n\\n2) In ∆ABC, A=50°, B = 75°, C=?\\n\\nA)55°\\tB)60°\\tC)65°\\tD)75°\\n\\nWhich figure is formed by three non collinear points. A)line\\tB)Ray\\tC) Triangle\\tD) Circle\\n\\nHow many points are there in intersection of two distinct lines?\\n\\nInfinite\\tB) One\\tC) Two\\tD) Not a single\\n\\nTrue or false.\\t(4)\\n\\nsum of interior angle is 90°\\n\\ncomplementry angles are congruent. 3)every segment has only one midpoint.\\n\\n4)the sum of measures of all angles of a triangle is 180°.\\n\\nA) Find the distance with the help of the number line given below (any2).\\t(2)\\n\\n1) d(B,E)\\t2)d(O,E)\\t3)(P,D)\\n\\nA) Prove: The sum of measures of all angles of a triangle is 180°.\\t(4)'), Document(metadata={'source': '/tmp/tmpau38k8tr/maricogpt/doc_9th-SB.docx_321d7910-ac1b-4165-9641-5f8e4df745fc'}, page_content='A) Find the distance with the help of the number line given below (any2).\\t(2)\\n\\n1) d(B,E)\\t2)d(O,E)\\t3)(P,D)\\n\\nA) Prove: The sum of measures of all angles of a triangle is 180°.\\t(4)\\n\\nIn figure,line AB || line CD and line PQ is transversal, measures of one of angle is given. hence find the measures of the following angles.\\t(4)\\n\\nART\\n\\nCTQ\\n\\nDTQ\\n\\nPRB\\n\\nUsing the information in adjoining figure, find the measures of angle a, b and c.\\t(4)')]\n"
     ]
    }
   ],
   "source": [
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def CreateRetriever(document_id,sas_url):\n",
    "    try:\n",
    "        loader = PyPDFLoader(sas_url)\n",
    "        pages = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        splits = text_splitter.split_documents(pages)\n",
    "\n",
    "        vector_store_address: str = \"https://inhouse-ai-search-service.search.windows.net\"\n",
    "        vector_store_password: str = \"gwCjVtUk7IpgpvjMhgM3Dgdt1noxYUIKGKUuNB4me2AzSeCc1Ccf\"\n",
    "        \n",
    "        embeddings = AzureOpenAIEmbeddings(azure_deployment=\"text-embedding-ada\", api_key=\"df22c6e2396e40c485adc343c9a969ed\",api_version=\"2024-02-15-preview\",azure_endpoint= \"https://milazdalle.openai.azure.com/\")\n",
    "\n",
    "        index_name: str = \"marico-gpt-test\"\n",
    "        embedding_function = embeddings.embed_query\n",
    "        fields = [\n",
    "        SimpleField(\n",
    "            name=\"id\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            key=True,\n",
    "            filterable=True,\n",
    "        ),\n",
    "        SimpleField(\n",
    "            name=\"original_document_id\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            key=False,\n",
    "            filterable=True,\n",
    "        ),\n",
    "        SearchableField(\n",
    "            name=\"content\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            searchable=True,\n",
    "        ),\n",
    "        SearchField(\n",
    "            name=\"content_vector\",\n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "            searchable=True,\n",
    "            vector_search_dimensions=len(embedding_function(\"Text\")),\n",
    "            vector_search_profile_name=\"myHnswProfile\",\n",
    "        ),\n",
    "        SearchableField(\n",
    "            name=\"metadata\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            filterable = True,\n",
    "            searchable=True,\n",
    "        ),\n",
    "\n",
    "        SearchableField(\n",
    "            name=\"title\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            searchable=True,\n",
    "            filterable=True,\n",
    "        )\n",
    "        \n",
    "        ]\n",
    "        vector_store: AzureSearch = AzureSearch(\n",
    "        azure_search_endpoint=vector_store_address,\n",
    "        azure_search_key=vector_store_password,\n",
    "        index_name=index_name,\n",
    "        embedding_function=embedding_function,\n",
    "        fields=fields\n",
    "        )\n",
    "\n",
    "        vector_ids = vector_store.add_texts(\n",
    "        texts= [item.page_content for item in splits],\n",
    "        metadatas=[\n",
    "            {\n",
    "                'id': f\"doc_{document_id}_{index}\", \n",
    "                'title': 'Testing_123',\n",
    "                'original_document_id': f'doc_{document_id}', \n",
    "            }\n",
    "            for index, item in enumerate(splits)\n",
    "        ]\n",
    "        )\n",
    "\n",
    "        retriever = vector_store.as_retriever(\n",
    "        # filter = f\"original_document_id eq 'doc_{document_id}'\"\n",
    "            # 'filter': {'metadata': f\"{{\\\"id\\\": \\\"doc_123_20\\\", \\\"title\\\": \\\"Testing_123\\\", \\\"original_document_id\\\": \\\"doc_{document_id}\\\"}}\"} \n",
    "            k = 3,\n",
    "            search_kwargs={\"filters\": f\"original_document_id eq 'doc_{document_id}'\"}\n",
    "        )\n",
    "\n",
    "        return retriever\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    ScoringProfile,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    TextWeights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_address: str = \"https://inhouse-ai-search-service.search.windows.net\"\n",
    "vector_store_password: str = \"gwCjVtUk7IpgpvjMhgM3Dgdt1noxYUIKGKUuNB4me2AzSeCc1Ccf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(azure_deployment=\"text-embedding-ada\", api_key=\"df22c6e2396e40c485adc343c9a969ed\",api_version=\"2024-02-15-preview\",azure_endpoint= \"https://milazdalle.openai.azure.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-search-documents==11.4.0\n",
      "  Downloading azure_search_documents-11.4.0-py3-none-any.whl (283 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.8/283.8 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: azure-core<2.0.0,>=1.28.0 in ./bvenv/lib/python3.10/site-packages (from azure-search-documents==11.4.0) (1.30.2)\n",
      "Requirement already satisfied: isodate>=0.6.0 in ./bvenv/lib/python3.10/site-packages (from azure-search-documents==11.4.0) (0.6.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in ./bvenv/lib/python3.10/site-packages (from azure-search-documents==11.4.0) (1.1.28)\n",
      "Requirement already satisfied: requests>=2.21.0 in ./bvenv/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.28.0->azure-search-documents==11.4.0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in ./bvenv/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.28.0->azure-search-documents==11.4.0) (4.12.2)\n",
      "Requirement already satisfied: six>=1.11.0 in ./bvenv/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.28.0->azure-search-documents==11.4.0) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./bvenv/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-search-documents==11.4.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./bvenv/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-search-documents==11.4.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./bvenv/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-search-documents==11.4.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./bvenv/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-search-documents==11.4.0) (2024.7.4)\n",
      "Installing collected packages: azure-search-documents\n",
      "  Attempting uninstall: azure-search-documents\n",
      "    Found existing installation: azure-search-documents 11.5.1\n",
      "    Uninstalling azure-search-documents-11.5.1:\n",
      "      Successfully uninstalled azure-search-documents-11.5.1\n",
      "Successfully installed azure-search-documents-11.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install azure-search-documents==11.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name: str = \"marico-gpt-test-123456\"\n",
    "embedding_function = embeddings.embed_query\n",
    "fields = [\n",
    "SimpleField(\n",
    "    name=\"id\",\n",
    "    type=SearchFieldDataType.String,\n",
    "    key=True,\n",
    "    filterable=True,\n",
    "),\n",
    "SimpleField(\n",
    "    name=\"original_document_id\",\n",
    "    type=SearchFieldDataType.String,\n",
    "    key=False,\n",
    "    filterable=True,\n",
    "),\n",
    "SearchableField(\n",
    "    name=\"content\",\n",
    "    type=SearchFieldDataType.String,\n",
    "    searchable=True,\n",
    "),\n",
    "SearchField(\n",
    "    name=\"content_vector\",\n",
    "    type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "    searchable=True,\n",
    "    # retrievable =True,\n",
    "    vector_search_dimensions=len(embedding_function(\"Text\")),\n",
    "    vector_search_profile_name=\"myHnswProfile\",\n",
    "),\n",
    "SearchableField(\n",
    "    name=\"metadata\",\n",
    "    type=SearchFieldDataType.String,\n",
    "    filterable = True,\n",
    "    searchable=True,\n",
    "),\n",
    "\n",
    "SearchableField(\n",
    "    name=\"title\",\n",
    "    type=SearchFieldDataType.String,\n",
    "    searchable=True,\n",
    "    filterable=True,\n",
    ")\n",
    "\n",
    "]\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "azure_search_endpoint=vector_store_address,\n",
    "azure_search_key=vector_store_password,\n",
    "index_name=index_name,\n",
    "embedding_function=embedding_function,\n",
    "fields=fields\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Node:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.next = None\n",
    "\n",
    "class LinkedList:\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "\n",
    "    def append(self, data):\n",
    "        new_node = Node(data)\n",
    "        if not self.head:\n",
    "            self.head = new_node\n",
    "            return\n",
    "        last = self.head\n",
    "        while last.next:\n",
    "            last = last.next\n",
    "        last.next = new_node\n",
    "\n",
    "    def print_list(self):\n",
    "        current = self.head\n",
    "        while current:\n",
    "            print(current.data, end=\" -> \")\n",
    "            current = current.next\n",
    "        print(\"None\")\n",
    "\n",
    "    def reverse(self):\n",
    "        prev = None\n",
    "        current = self.head\n",
    "        while current:\n",
    "            next_node = current.next\n",
    "            current.next = prev\n",
    "            prev = current\n",
    "            current = next_node\n",
    "        self.head = prev\n",
    "\n",
    "# Example usage:\n",
    "ll = LinkedList()\n",
    "ll.append(1)\n",
    "ll.append(2)\n",
    "ll.append(3)\n",
    "ll.append(4)\n",
    "\n",
    "print(\"Original Linked List:\")\n",
    "ll.print_list()\n",
    "\n",
    "ll.reverse()\n",
    "\n",
    "print(\"Reversed Linked List:\")\n",
    "ll.print_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_str = \"DefaultEndpointsProtocol=https;AccountName=maricogpt;AccountKey=qWBQYmrXPuHjMGcT3NUi9fZ+6AmPtJI2bKiX7CZ4uFsSY0IvPERIt35eBBeoPscXGG8VKPYRRK1t+ASt0V6R9w==;EndpointSuffix=core.windows.net\"\n",
    "container_name = \"maricogpt\"  \n",
    "blob_name = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'connect_str' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loader \u001b[38;5;241m=\u001b[39m AzureBlobStorageFileLoader(conn_str\u001b[38;5;241m=\u001b[39m\u001b[43mconnect_str\u001b[49m,container \u001b[38;5;241m=\u001b[39m container_name, blob_name\u001b[38;5;241m=\u001b[39mblob_name)\n\u001b[1;32m      2\u001b[0m pages \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m      3\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'connect_str' is not defined"
     ]
    }
   ],
   "source": [
    "loader = AzureBlobStorageFileLoader(conn_str=connect_str,container = container_name, blob_name=blob_name)\n",
    "pages = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in ./bvenv/lib/python3.10/site-packages (0.11.4)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in ./bvenv/lib/python3.10/site-packages (from pdfplumber) (4.30.0)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in ./bvenv/lib/python3.10/site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in ./bvenv/lib/python3.10/site-packages (from pdfplumber) (10.4.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in ./bvenv/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in ./bvenv/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (43.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in ./bvenv/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.0)\n",
      "Requirement already satisfied: pycparser in ./bvenv/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pdfplumber\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = \"/home/admharshila/harshil/docker_test/MaricoGPT/Backend/5041454865.PDF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pages [<Page:1>, <Page:2>]\n",
      "page <Page:1>\n",
      "page <Page:2>\n"
     ]
    }
   ],
   "source": [
    "with pdfplumber.open(pdf) as pdf:\n",
    "    text = []\n",
    "    table = []\n",
    "    pages = pdf.pages[:]\n",
    "    print(\"pages\",pages)\n",
    "    for page in pages:\n",
    "        print(\"page\",page)\n",
    "\n",
    "        text.append(page.extract_text())\n",
    "        table.extend(page.extract_tables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reliance Retail Limited\\nSupplier: Marico Limited Code :10002199\\nPerfect Traders, Laxmi NarayanEstate, Bajrang Lane GSTIN NO :24AAACM7493G1ZD\\nNear Aslali By Pass Bridge, N.H.No.Ahmedabad Vendor Type : REGISTERED\\nGujarat - 382427\\nGOODS RECEIPT NOTE No. : 5041454865 Date: 19.09.2024\\nConsignee : RRL VF Surat Vesma DC Vendor invoice no : 5441105719\\nReliance Retail Limited\\nBlock No 533 534 Near Mangalam 93\\n534 Canal Road Vesma Chokdi Surat\\nSURAT\\nGujarat -396475\\nGSTIN NO. : 24AABCR1718E1ZV\\nPO Number : 5106222547 Date : 13.09.2024\\nDelivery Addr: RRL VF Surat Vesma DC Delivery No : 198626201\\nReliance Retail Limited Transporter Details:\\nBlock No 533 534 Near Mangalam 93 Name : Dhtc Logistics Limited\\n534 Canal Road Vesma Chokdi Surat Consignment Note : 487341 C/N Date : 17.09.2024\\nSURAT Truck/ Lorry/ Carrier No: GJ23Y2915\\nGujarat - 396475 Delivery Challan No: 5441105719\\nGSTIN NO. : 24AABCR1718E1ZV\\nPage Number : 1 of 2\\nS No Article Item Description UoM Challan Recieved Accepted Reason\\nBatch EAN Number Vendor Article No Qty Qty Qty/MRP Short Description\\n1 490000057 Saffola Gold Blnd Edbl Vgtbl Oil 1l Pp EA 240 240 240\\n8901088017381\\n160.00\\n2 490002123 Parachute Coconut Oil 100 Ml Btl EA 384 384 384\\n89002940\\n43.00\\n3 490002124 Parachute Coconut Oil 200ml Pet EA 180 180 180\\n8901088000345\\n97.00\\n4 490002170 Hair Care Mstr Fruit Ns Hr Oil 300ml Pe EA 60 60 60\\n8901088193801\\n190.00\\n5 490437775 Saffola Actv Blnd Edbl Vegtbl Oil 5l Ca EA 52 52 52\\n8901088034616\\n805.00\\n6 490710232 Saffola Oats 1 Kg(free 300g Saf Oats) P EA 16 16 16\\n8901088055772\\n235.00\\n7 490985424 Saffola Oats Classic Masala 38g Pp EA 560 560 560\\n8901088068734\\n17.00\\n8 490985425 Saffola Pepy Tomato Inst Msl Oats 38g P EA 280 280 280\\n8901088068741\\n17.00\\n9 490985426 Saffola Veg Twst Instnt Msla Oats 38g P EA 280 280 280\\n8901088068758\\n17.00\\n10 491294658 Parachute Coconut Oil 600 Ml Pet EA 96 96 96\\n8901088102872\\n273.00\\n11 491319630 Saffola Masala Oats Clsic Masala 250g P EA 144 144 144\\n8901088171755\\n149.00\\n12 491319631 Saffola Masala Oats Veggie Twist 250 Gp EA 96 96 96\\n8901088745109\\n149.00\\n13 491420619 Saffola Msl Oats Pepy Tomto 500g Pp EA 30 30 30\\n8901088129817\\n235.00\\n14 491695604 Saffola Honey Active 250g Glass Jar EA 48 48 48\\n8901088069076\\n99.00\\nReason : Goods receipt for purchase order into warehouse/stores\\nRRL VF Surat Vesma DC\\nThis is a computer generated document not ,requiring any signature Signature Title Date\\nREGD OFFICE :- 3rd Floor, Court House Lokmanya Tilak Marg, Dhobi Talao, Mumbai 400002\\nNote: - Received qty refers to physically received quantity.\\nPayment is being made basis preliminary inspection of the material supplied by you. However, if any quality /packaging/compliance issue is observed by us\\nsubsequently during usage/packing in the material supplied, then same would be rejected. Cost of such rejected material would be recoverable from you or\\nyou may supply good quality material in lieu of same free of cost.', 'Reliance Retail Limited\\nSupplier: Marico Limited Code :10002199\\nPerfect Traders, Laxmi NarayanEstate, Bajrang Lane GSTIN NO :24AAACM7493G1ZD\\nNear Aslali By Pass Bridge, N.H.No.Ahmedabad Vendor Type : REGISTERED\\nGujarat - 382427\\nGOODS RECEIPT NOTE No. : 5041454865 Date: 19.09.2024\\nConsignee : RRL VF Surat Vesma DC Vendor invoice no : 5441105719\\nReliance Retail Limited\\nBlock No 533 534 Near Mangalam 93\\n534 Canal Road Vesma Chokdi Surat\\nSURAT\\nGujarat -396475\\nGSTIN NO. : 24AABCR1718E1ZV\\nPO Number : 5106222547 Date : 13.09.2024\\nDelivery Addr: RRL VF Surat Vesma DC Delivery No : 198626201\\nReliance Retail Limited Transporter Details:\\nBlock No 533 534 Near Mangalam 93 Name : Dhtc Logistics Limited\\n534 Canal Road Vesma Chokdi Surat Consignment Note : 487341 C/N Date : 17.09.2024\\nSURAT Truck/ Lorry/ Carrier No: GJ23Y2915\\nGujarat - 396475 Delivery Challan No: 5441105719\\nGSTIN NO. : 24AABCR1718E1ZV\\nPage Number : 2 of 2\\nS No Article Item Description UoM Challan Recieved Accepted Reason\\nBatch EAN Number Vendor Article No Qty Qty Qty/MRP Short Description\\n15 491695606 Saffola Honey Active 1kg Glass Jar EA 72 72 72\\n8901088069083\\n495.00\\n16 492339249 Saffola Oodles Yummy Masala Nodls 46g P EA 144 144 144\\n8901088205221\\n25.00\\n17 492519502 Prcht Advn Jsmn Gld Ns Ccnt Ho 300ml Pe EA 144 144 144\\n8901088205993\\n170.00\\n18 492862015 Saffola Eggless Mayonnaise Ssp 700g Pch EA 48 48 48\\n8901088081276\\n199.00\\n19 492862017 Saffola Pnut Btr Wth Jgry Crnchy 350gpe EA 24 24 24\\n8901088081313\\n149.00\\n20 493619312 Saffola Mayo Veg Eggless 80g Pch EA 72 72 72\\n8901088081191\\n50.00\\n21 494336387 Prcte Adv Bhrngrj Cnut Hr Oil 200ml Btl EA 48 48 48\\n8901088752466\\n150.00\\n22 494336821 Parachute 100% Pure Cocnut Oil 450ml Pe EA 240 240 240\\n8901088758994\\n187.00\\n23 494357148 Saffola Muesli Berry Crunch 185g Pp EA 30 30 30\\n8901088766951\\n149.00\\n24 494357290 Saffola Creamy Oats 300+300g Pp EA 24 24 24\\n8901088760454\\n138.00\\nTotal Qty UOM wise EA 3,312.000 3,312.000 3,312.000\\nReason : Goods receipt for purchase order into warehouse/stores\\nRRL VF Surat Vesma DC\\nThis is a computer generated document not ,requiring any signature Signature Title Date\\nREGD OFFICE :- 3rd Floor, Court House Lokmanya Tilak Marg, Dhobi Talao, Mumbai 400002\\nNote: - Received qty refers to physically received quantity.\\nPayment is being made basis preliminary inspection of the material supplied by you. However, if any quality /packaging/compliance issue is observed by us\\nsubsequently during usage/packing in the material supplied, then same would be rejected. Cost of such rejected material would be recoverable from you or\\nyou may supply good quality material in lieu of same free of cost.']\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Reliance Retail Limited', None, None, None, None, None, None, None], ['Supplier: Marico Limited Code :10002199\\nPerfect Traders, Laxmi NarayanEstate, Bajrang Lane GSTIN NO :24AAACM7493G1ZD\\nNear Aslali By Pass Bridge, N.H.No.Ahmedabad Vendor Type : REGISTERED\\nGujarat - 382427', None, None, None, None, None, None, None], ['GOODS RECEIPT NOTE No. : 5041454865 Date: 19.09.2024', None, None, None, None, None, None, None], ['Consignee : RRL VF Surat Vesma DC Vendor invoice no : 5441105719\\nReliance Retail Limited\\nBlock No 533 534 Near Mangalam 93\\n534 Canal Road Vesma Chokdi Surat\\nSURAT\\nGujarat -396475\\nGSTIN NO. : 24AABCR1718E1ZV\\nPO Number : 5106222547 Date : 13.09.2024\\nDelivery Addr: RRL VF Surat Vesma DC Delivery No : 198626201\\nReliance Retail Limited Transporter Details:\\nBlock No 533 534 Near Mangalam 93 Name : Dhtc Logistics Limited\\n534 Canal Road Vesma Chokdi Surat Consignment Note : 487341 C/N Date : 17.09.2024\\nSURAT Truck/ Lorry/ Carrier No: GJ23Y2915\\nGujarat - 396475 Delivery Challan No: 5441105719\\nGSTIN NO. : 24AABCR1718E1ZV\\nPage Number : 2 of 2', None, None, None, None, None, None, None], ['S No', 'Article\\nBatch', 'Item Description\\nEAN Number Vendor Article No', 'UoM', 'Challan\\nQty', 'Recieved\\nQty', 'Accepted\\nQty/MRP', 'Reason\\nShort Description'], ['15\\n16\\n17\\n18\\n19\\n20\\n21\\n22\\n23\\n24', '491695606\\n492339249\\n492519502\\n492862015\\n492862017\\n493619312\\n494336387\\n494336821\\n494357148\\n494357290', 'Saffola Honey Active 1kg Glass Jar\\n8901088069083\\nSaffola Oodles Yummy Masala Nodls 46g P\\n8901088205221\\nPrcht Advn Jsmn Gld Ns Ccnt Ho 300ml Pe\\n8901088205993\\nSaffola Eggless Mayonnaise Ssp 700g Pch\\n8901088081276\\nSaffola Pnut Btr Wth Jgry Crnchy 350gpe\\n8901088081313\\nSaffola Mayo Veg Eggless 80g Pch\\n8901088081191\\nPrcte Adv Bhrngrj Cnut Hr Oil 200ml Btl\\n8901088752466\\nParachute 100% Pure Cocnut Oil 450ml Pe\\n8901088758994\\nSaffola Muesli Berry Crunch 185g Pp\\n8901088766951\\nSaffola Creamy Oats 300+300g Pp\\n8901088760454', 'EA\\nEA\\nEA\\nEA\\nEA\\nEA\\nEA\\nEA\\nEA\\nEA', '72\\n144\\n144\\n48\\n24\\n72\\n48\\n240\\n30\\n24', '72\\n144\\n144\\n48\\n24\\n72\\n48\\n240\\n30\\n24', '72\\n495.00\\n144\\n25.00\\n144\\n170.00\\n48\\n199.00\\n24\\n149.00\\n72\\n50.00\\n48\\n150.00\\n240\\n187.00\\n30\\n149.00\\n24\\n138.00', ''], ['Total Qty UOM wise', None, None, 'EA', '3,312.000', '3,312.000', '3,312.000', '']]\n"
     ]
    }
   ],
   "source": [
    "print(table[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(table[2:], columns = table[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<div className=\"chatTitles\">\n",
    "  {chatSessions.map((session) => (\n",
    "    <div\n",
    "      key={session.id}\n",
    "      className={`chatTitle ${session.id === activeSessionId ? \"active\" : \"\"} ${isSidebarCollapsed ? \"collapsed\" : \"\"}`}\n",
    "    >\n",
    "      {session.isEditing ? (\n",
    "        <input\n",
    "          type=\"text\"\n",
    "          value={session.title}\n",
    "          onChange={(e) => handleTitleChange(session.id, e.target.value)}\n",
    "          onBlur={() => handleTitleSave(session.id)}\n",
    "          onKeyDown={(e) => handleKeyDown(e, session.id)}\n",
    "          className=\"chatTitleInput\"\n",
    "        />\n",
    "      ) : (\n",
    "        <span\n",
    "          className=\"chatTitleText\"\n",
    "          onClick={() => handleSessionClick(session.id)}\n",
    "        >\n",
    "          {session.title}\n",
    "        </span>\n",
    "      )}\n",
    "      <div className=\"threeDotMenu\">\n",
    "        <button className=\"threeDotButton\">...</button>\n",
    "        <div className=\"menuOptions\">\n",
    "          <button onClick={() => handleEdit(session.id)}>Edit</button>\n",
    "          <button onClick={() => handleDelete(session.id)}>Delete</button>\n",
    "        </div>\n",
    "      </div>\n",
    "    </div>\n",
    "  ))}\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".chatTitles {\n",
    "  display: flex;\n",
    "  flex-direction: column;\n",
    "  margin-top: 5rem;\n",
    "  padding-left: 10px;\n",
    "  cursor: pointer;\n",
    "  overflow-y: auto;\n",
    "  overflow-x: visible;\n",
    "  max-height: 450px;\n",
    "  scrollbar-width: thin;\n",
    "  scrollbar-color: #888 #000000;\n",
    "}    \n",
    "\n",
    ".chatTitles::-webkit-scrollbar-thumb {      \n",
    "  background: #888;\n",
    "  border-radius: 10px;\n",
    "  transition: background-color 0.3s ease;\n",
    "  width: 20px;\n",
    "}\n",
    "\n",
    ".chatTitles::-webkit-scrollbar-thumb:hover {\n",
    "  background: #555;\n",
    "}\n",
    "\n",
    ".chatTitle {\n",
    "  display: flex;\n",
    "  align-items: center;\n",
    "  justify-content: space-between;\n",
    "  margin-bottom: 0.1rem;\n",
    "  margin-right: 7px;\n",
    "  cursor: pointer;\n",
    "  background-color: rgb(23, 23, 23);\n",
    "  padding-right: 10px;\n",
    "}\n",
    "\n",
    ".chatTitle.active {\n",
    "  background-color: #333;\n",
    "  border-radius: 1rem;\n",
    "}\n",
    "\n",
    ".chatTitle.collapsed {\n",
    "  display: none;\n",
    "}\n",
    "\n",
    ".chatTitleText {\n",
    "  flex-grow: 1;\n",
    "  white-space: nowrap;\n",
    "  overflow: hidden;\n",
    "  text-overflow: ellipsis;\n",
    "  padding: 0.8rem 2rem;\n",
    "  color: #ffffff;\n",
    "  font-size: 14px;\n",
    "  cursor: pointer;\n",
    "  border-radius: 1rem;\n",
    "}\n",
    "\n",
    ".threeDotMenu {\n",
    "  position: relative;\n",
    "  display: inline-block;\n",
    "}\n",
    "\n",
    ".threeDotButton {\n",
    "  border: none;\n",
    "  background: none;\n",
    "  cursor: pointer;\n",
    "  color: rgb(151, 147, 147);\n",
    "  font-size: 2rem;\n",
    "  padding: 0 5px;\n",
    "}\n",
    "\n",
    ".menuOptions {\n",
    "  position: absolute;\n",
    "  right: 0;\n",
    "  top: 100%;\n",
    "  background-color: #000000;\n",
    "  min-width: 100px;\n",
    "  box-shadow: 0px 8px 16px rgba(0, 0, 0, 0.2);\n",
    "  z-index: 1;\n",
    "  border-radius: 4px;\n",
    "  display: none;\n",
    "}\n",
    "\n",
    ".threeDotMenu:hover .menuOptions {\n",
    "  display: block;\n",
    "}\n",
    "\n",
    ".menuOptions button {\n",
    "  width: 100%;\n",
    "  padding: 12px 20px;\n",
    "  text-align: left;\n",
    "  border: none;\n",
    "  background: none;\n",
    "  cursor: pointer;\n",
    "  font-size: 1.4rem;\n",
    "  color: #ffffff;\n",
    "  transition: background-color 0.3s ease, color 0.3s ease;\n",
    "}\n",
    "\n",
    ".menuOptions button:hover {\n",
    "  background-color: #726e6e;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/delete_normal_chat\")\n",
    "def get_all_chat_histories(input_model: UsernameModel):\n",
    "    try:\n",
    "        query = \"SELECT top 10 * FROM c where STARTSWITH(c.id, @prefix ) = true order by c.Date_uploaded desc\"\n",
    "        query = \"Delete * from c where c.id = @prefix\"\n",
    "        params = [{\"name\": \"@prefix\", \"value\": input_model.session_id}]\n",
    "        container.query_items(query=query,parameters=params,enable_cross_partition_query=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before await 0\n",
      "<async_generator object write at 0x7fbff05cc140> 0\n",
      "After await 0\n",
      "Before await 1\n",
      "<async_generator object write at 0x7fbff05cc1c0> 10\n",
      "After await 1\n",
      "Before await 2\n",
      "<async_generator object write at 0x7fbff05cc1c0> 20\n",
      "After await 2\n",
      "Before await 3\n",
      "<async_generator object write at 0x7fbff05cc1c0> 30\n",
      "After await 3\n",
      "Before await 4\n",
      "<async_generator object write at 0x7fbff05cc1c0> 40\n",
      "After await 4\n",
      "Before await 5\n",
      "<async_generator object write at 0x7fbff05cc1c0> 50\n",
      "After await 5\n",
      "Before await 6\n",
      "<async_generator object write at 0x7fbff05cc1c0> 60\n",
      "After await 6\n",
      "Before await 7\n",
      "<async_generator object write at 0x7fbff05cc1c0> 70\n",
      "After await 7\n",
      "Before await 8\n",
      "<async_generator object write at 0x7fbff05cc1c0> 80\n",
      "After await 8\n",
      "Before await 9\n",
      "<async_generator object write at 0x7fbff05cc1c0> 90\n",
      "After await 9\n"
     ]
    }
   ],
   "source": [
    "async def write(i):\n",
    "    time.sleep(10)\n",
    "    yield i \n",
    "\n",
    "async def write_2(i):\n",
    "    time.sleep(0)\n",
    "    return i*10\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Before await\",i)\n",
    "    print(write(i), await write_2(i))\n",
    "    print(\"After await\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure.cosmos\n",
      "  Using cached azure_cosmos-4.7.0-py3-none-any.whl (252 kB)\n",
      "Requirement already satisfied: azure-core>=1.25.1 in ./bvenv/lib/python3.10/site-packages (from azure.cosmos) (1.30.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in ./bvenv/lib/python3.10/site-packages (from azure.cosmos) (4.12.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in ./bvenv/lib/python3.10/site-packages (from azure-core>=1.25.1->azure.cosmos) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in ./bvenv/lib/python3.10/site-packages (from azure-core>=1.25.1->azure.cosmos) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./bvenv/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.25.1->azure.cosmos) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./bvenv/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.25.1->azure.cosmos) (2024.7.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./bvenv/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.25.1->azure.cosmos) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./bvenv/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.25.1->azure.cosmos) (2.2.2)\n",
      "Installing collected packages: azure.cosmos\n",
      "Successfully installed azure.cosmos-4.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install azure.cosmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Backend.DocAI import CallRetriever\n",
    "import cloudpickle\n",
    "from azure.storage.blob import BlobServiceClient,generate_blob_sas,BlobSasPermissions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_str = \"DefaultEndpointsProtocol=https;AccountName=maricogpt;AccountKey=qWBQYmrXPuHjMGcT3NUi9fZ+6AmPtJI2bKiX7CZ4uFsSY0IvPERIt35eBBeoPscXGG8VKPYRRK1t+ASt0V6R9w==;EndpointSuffix=core.windows.net\"\n",
    "container_name = \"maricogpt\"  \n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "container_client = blob_service_client.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_retriever():\n",
    "    document_id = \"doc_Harshil_5b72f401-d75c-46e1-868f-60a86de8353e\"\n",
    "    blob_name = document_id\n",
    "\n",
    "    Retriever = await CallRetriever(document_id = document_id,connect_str=connect_str,container_name=container_name,blob_name=blob_name)\n",
    "    print(\"Retriever Created Sucessfully\")\n",
    "    return Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cloudpickle\n",
      "  Downloading cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: cloudpickle\n",
      "Successfully installed cloudpickle-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "CACHE_DIR = \"retriever_cache\"\n",
    "\n",
    "# Ensure the cache directory exists\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dump() missing 1 required positional argument: 'file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcloudpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: dump() missing 1 required positional argument: 'file'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.retrievers.azure_ai_search.AzureAISearchRetriever'>\n",
      "service_name='inhouse-ai-search-service' index_name='marico-gpt' api_key='gwCjVtUk7IpgpvjMhgM3Dgdt1noxYUIKGKUuNB4me2AzSeCc1Ccf' top_k=5\n"
     ]
    }
   ],
   "source": [
    "# retriever = await create_retriever()\n",
    "print(type(retriever))\n",
    "file = os.path.join(CACHE_DIR, f\"retriever.pkl\")\n",
    "with open(file, \"wb\") as f:\n",
    "    cloudpickle.dump(retriever, f)\n",
    "# ser = pickle.dumps(retriever.t)\n",
    "with open(file, \"rb\") as f:\n",
    "    ret = cloudpickle.load(f)\n",
    "\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import AzureAISearchRetriever\n",
    "retriever = AzureAISearchRetriever(\n",
    "    content_key=\"content\", top_k=5, index_name=\"marico-gpt\",service_name = \"inhouse-ai-search-service\",api_key = \"gwCjVtUk7IpgpvjMhgM3Dgdt1noxYUIKGKUuNB4me2AzSeCc1Ccf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.retrievers.azure_ai_search.AzureAISearchRetriever'>\n"
     ]
    }
   ],
   "source": [
    "print(type(retriever))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for AzureSearchVectorStoreRetriever\nvectorstore\n  field required (type=value_error.missing)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mazuresearch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureSearchVectorStoreRetriever\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Serialize the class to a bytes object\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mAzureSearchVectorStoreRetriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnect_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m...\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontainer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m...\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m...\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m serialized_class \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(b)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(serialized_class)\n",
      "File \u001b[0;32m~/harshil/docker_test/MaricoGPT/Backend/bvenv/lib/python3.10/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for AzureSearchVectorStoreRetriever\nvectorstore\n  field required (type=value_error.missing)"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearchVectorStoreRetriever\n",
    "\n",
    "# Serialize the class to a bytes object\n",
    "b = AzureSearchVectorStoreRetriever(connect_str=\"...\", container_name=\"...\", blob_name=\"...\")\n",
    "serialized_class = pickle.dumps(b)\n",
    "\n",
    "print(serialized_class)\n",
    "# Deserialize the class from the bytes object\n",
    "loaded_class = pickle.loads(serialized_class)\n",
    "\n",
    "# Verify that the loaded class is the same as the original\n",
    "print(loaded_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_store = {\n",
    "    'session123': {\n",
    "        'title': 'example_title',\n",
    "        'username': 'example_user',\n",
    "        'token_details': 'old_token'\n",
    "    }\n",
    "}\n",
    "\n",
    "{\n",
    "        \"timestamp\": str(datetime.now()),\n",
    "        \"input_tokens\": input_tokens,\n",
    "        \"output_tokens\": output_tokens\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_token_details(session_id,title, input_tokens,output_tokens,answered):\n",
    "    tokens = {\n",
    "        \"timestamp\": str(datetime.now()),\n",
    "        \"input_tokens\": input_tokens,\n",
    "        \"output_tokens\": output_tokens,\n",
    "        \"answered\" : answered\n",
    "    }\n",
    "    \n",
    "    if session_id in token_store:\n",
    "        token_store[session_id]['token_details'].append(tokens)\n",
    "        return\n",
    "    else:\n",
    "        load_token_store_from_cosmosdb(session_id)\n",
    "        if session_id in token_store:\n",
    "            token_store[session_id]['token_details'].append(tokens)\n",
    "            return\n",
    "    token_store[session_id] = {\n",
    "        'title': title,\n",
    "        'username': session_id,\n",
    "        'token_details': [tokens] \n",
    "    }\n",
    "        \n",
    "def upload_token_store_to_cosmosdb():\n",
    "    global token_store\n",
    "    for session_id, token_data in token_store.items():\n",
    "        token_data['id'] = session_id\n",
    "        token_data[\"key\"] = session_id\n",
    "        token_data['Date_uploaded'] = str(datetime.now())\n",
    "        token_container.upsert_item(\n",
    "            token_data,\n",
    "        )\n",
    "    for x in token_store.keys():\n",
    "        logger.info(f\"Chat model - Session_ID ({x} : Chat history saved to CosmosDB sucessfully\")\n",
    "    token_store.clear()\n",
    "    print(\"Store cleared:\", token_store)\n",
    "    \n",
    "    \n",
    "def load_token_store_from_cosmosdb(session_idx):\n",
    "    global Store\n",
    "    try:\n",
    "        item = token_container.read_item(item=session_idx,partition_key=session_idx)\n",
    "        token_store[session_idx] = item\n",
    "    except CosmosResourceNotFoundError:\n",
    "        pass\n",
    "    print(token_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting redis\n",
      "  Using cached redis-5.1.1-py3-none-any.whl (261 kB)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in ./bvenv/lib/python3.10/site-packages (from redis) (4.0.3)\n",
      "Installing collected packages: redis\n",
      "Successfully installed redis-5.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "\n",
    "   # Replace with your Redis cache connection string and key\n",
    "redis_host = 'maricogpt.redis.cache.windows.net'\n",
    "redis_port = 6380  # Default port for SSL\n",
    "redis_password = 'oaWKR5Jp9Frc1D4OrMXWh3YQlnX9mciRpAzCaKZLTS4='\n",
    "\n",
    "r = redis.StrictRedis(host=redis_host, port=redis_port,password= redis_password,ssl=True)\n",
    "\n",
    "try:\n",
    "    # Set a value in Redis\n",
    "    r.set('key', 'value')\n",
    "    # Retrieve the value from Redis\n",
    "    value = r.get('key')\n",
    "    print(value.decode('utf-8'))\n",
    "except redis.ConnectionError as e:\n",
    "    print(f\"Could not connect to Redis: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3]\n",
      "0 token\n"
     ]
    }
   ],
   "source": [
    "data = {\"token\":[2,3]}\n",
    "\n",
    "if \"token\" in data:\n",
    "    print(data[\"token\"])\n",
    "    \n",
    "for ind,i in enumerate(data):\n",
    "    print(ind,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'key': 1, 'Date_uploaded': '2024-10-21 10:39:02.530680', 'chat_details': [{'input_tokens': 0, 'timestamp': 0}, {'input_tokens': 1, 'timestamp': 1}, {'input_tokens': 2, 'timestamp': 2}, {'input_tokens': 3, 'timestamp': 3}, {'input_tokens': 4, 'timestamp': 4}, {'input_tokens': 5, 'timestamp': 5}, {'input_tokens': 6, 'timestamp': 6}, {'input_tokens': 7, 'timestamp': 7}, {'input_tokens': 8, 'timestamp': 8}, {'input_tokens': 9, 'timestamp': 9}]}\n"
     ]
    }
   ],
   "source": [
    "token_data = {} \n",
    "token_data['id'] = 1\n",
    "token_data[\"key\"] = 1\n",
    "token_data['Date_uploaded'] = str(datetime.now())\n",
    "token_data['chat_details'] = []\n",
    "\n",
    "for i in range(10):\n",
    "    token_data_per_chat = {\"input_tokens\":i,\"timestamp\": i}\n",
    "\n",
    "\n",
    "    token_data['chat_details'].append(token_data_per_chat)\n",
    "    \n",
    "print(token_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "if \"chat_details\" in token_data:\n",
    "    print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def CallRetriever(document_id: str,\n",
    "                       connect_str: Optional[str] = None,  # Not used for AzureAISearchRetriever\n",
    "                       container_name: Optional[str] = None,  # Not used for AzureAISearchRetriever\n",
    "                       blob_name: Optional[str] = None  # Not used for AzureAISearchRetriever\n",
    "                       ) -> AzureAISearchRetriever:\n",
    "    \n",
    "    service_name = \"inhouse-ai-search-service\"  \n",
    "    api_key = \"gwCjVtUk7IpgpvjMhgM3Dgdt1noxYUIKGKUuNB4me2AzSeCc1Ccf\"\n",
    "    index_name = \"marico-gpt\"\n",
    "    \n",
    "    \n",
    "    retriever = AzureAISearchRetriever(\n",
    "        service_name=service_name,\n",
    "        index_name=index_name,\n",
    "        api_version=\"2023-11-01\",  # You can update this to the latest version\n",
    "        api_key=api_key,\n",
    "        # Set number of results to return\n",
    "        top_k=20,\n",
    "        \n",
    "        # Set filter to match your current implementation\n",
    "        filter=f\"original_document_id eq '{document_id}'\",\n",
    "        \n",
    "        # Optional: Configure additional fields to retrieve        \n",
    "        # Use hybrid search (combines keyword and vector search)\n",
    "        # query_type=\"hybrid\"  # Options: \"simple\", \"semantic\", \"vector\", \"hybrid\"\n",
    "    )\n",
    "    \n",
    "    return retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_retriever():\n",
    "    document_id = \"doc_Harshil_5b72f401-d75c-46e1-868f-60a86de8353e\"\n",
    "    blob_name = document_id\n",
    "\n",
    "    Retriever = await CallRetriever(\"doc_Harshil_5b72f401-d75c-46e1-868f-60a86de8353e\")\n",
    "    print(\"Retriever Created Sucessfully\")\n",
    "    return Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redis_client.set(f\"Retriever:{session_id}\", json.dumps(conversation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Created Sucessfully\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "retriever = await create_retriever()\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.retrievers.azure_ai_search.AzureAISearchRetriever'>\n"
     ]
    }
   ],
   "source": [
    "print(type(retriever))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"\\x80\\x04\\x95\\xe9\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x8c.langchain_community.retrievers.azure_ai_search\\x94\\x8c\\x16AzureAISearchRetriever\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x08__dict__\\x94}\\x94(\\x8c\\x04name\\x94N\\x8c\\x04tags\\x94N\\x8c\\x08metadata\\x94N\\x8c\\x0cservice_name\\x94\\x8c\\x19inhouse-ai-search-service\\x94\\x8c\\nindex_name\\x94\\x8c\\nmarico-gpt\\x94\\x8c\\x07api_key\\x94\\x8c4gwCjVtUk7IpgpvjMhgM3Dgdt1noxYUIKGKUuNB4me2AzSeCc1Ccf\\x94\\x8c\\x0bapi_version\\x94\\x8c\\n2023-11-01\\x94\\x8c\\naiosession\\x94N\\x8c\\x0bcontent_key\\x94\\x8c\\x07content\\x94\\x8c\\x05top_k\\x94K\\x14\\x8c\\x06filter\\x94\\x8cJoriginal_document_id eq 'doc_Harshil_5b72f401-d75c-46e1-868f-60a86de8353e'\\x94u\\x8c\\x0e__fields_set__\\x94\\x8f\\x94(h\\x15h\\x0eh\\x0ch\\x10h\\x16h\\n\\x90\\x8c\\x1c__private_attribute_values__\\x94}\\x94ub.\"\n",
      "<class 'langchain_community.retrievers.azure_ai_search.AzureAISearchRetriever'>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "serialized_class = pickle.dumps(retriever)\n",
    "\n",
    "print(serialized_class)\n",
    "\n",
    "loaded_class = pickle.loads(serialized_class)\n",
    "\n",
    "print(type(loaded_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Conversation_model_RAG import Chatbot_RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is the character Tom Sawyer?The Context for the above question is not provided or didn't found in the document."
     ]
    }
   ],
   "source": [
    "output = await Chatbot_RAG(\"Who is Tom Sawyer\",\"doc_Harshil_5b72f401-d75c-46e1-868f-60a86de8353e\",loaded_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langgraph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mQueryAI\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m give_input\n",
      "File \u001b[0;32m~/harshil/docker_test/MaricoGPT/Backend/QueryAI.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql_database\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SQLDatabase\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MemorySaver\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quote\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langgraph'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
